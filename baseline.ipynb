{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdc897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['DEVICE_ID'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import mindspore as ms\n",
    "from mindspore import nn,Tensor\n",
    "from mindspore import context\n",
    "from mindspore.nn.metrics import Accuracy, MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3de353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN %\n",
      "U       0.00%\n",
      "V       0.00%\n",
      "W       0.00%\n",
      "U_x     0.00%\n",
      "U_y     0.00%\n",
      "U_z    52.83%\n",
      "V_x     0.00%\n",
      "V_y     0.00%\n",
      "V_z    52.83%\n",
      "W_x     0.00%\n",
      "W_y     0.00%\n",
      "W_Z    52.83%\n",
      "UU      0.00%\n",
      "UV      0.00%\n",
      "UW      0.00%\n",
      "VV      0.00%\n",
      "VW      0.00%\n",
      "WW      0.00%\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_csv('./data_train_input/data_train_input.csv')\n",
    "output_data = pd.read_csv('./data_train_output/data_train_output.csv')\n",
    "data = pd.concat([input_data,output_data],axis=1)\n",
    "print('NAN %')\n",
    "print((data.isna().sum()/data.shape[0]).apply(lambda x:format(x,'.2%')))\n",
    "data = data.drop(['U_z','V_z','W_Z'],axis=1)\n",
    "train = data.sample(frac=0.8,random_state=0)\n",
    "test = data.drop(train.index)\n",
    "x_train = train.iloc[:,:-6]\n",
    "y_train = train.iloc[:,-6:]\n",
    "x_test = test.iloc[:,:-6]\n",
    "y_test = test.iloc[:,-6:]\n",
    "x_train_ts = Tensor(np.array(x_train),ms.float32)\n",
    "y_train_ts = Tensor(np.array(y_train),ms.float32)\n",
    "x_test_ts = Tensor(np.array(x_test),ms.float32)\n",
    "y_test_ts = Tensor(np.array(y_test),ms.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5d370ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "dataset = {'feature':x_train_ts[:10],'label':y_train_ts[:10] }\n",
    "dataset = ds.NumpySlicesDataset(dataset, shuffle=False)\n",
    "# shuffled_dataset = dataset.shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d93aff09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mindspore.dataset.engine.datasets_user_defined.NumpySlicesDataset at 0x1d2a4ca6e50>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "06c0cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1868997, 9], dtype=Float32, value=\n",
       "[[ 1.17781997e+00,  1.16190001e-01,  0.00000000e+00 ... -1.85819507e-01,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 2.72589713e-01, -2.00515445e-02, -6.06241217e-03 ... -7.44985640e-02,  5.93658304e-03, -4.30153077e-03],\n",
       " [ 1.02515376e+00, -3.69837359e-02,  5.96646499e-03 ...  3.52185369e-02, -1.95971719e-04, -5.05584059e-03],\n",
       " ...\n",
       " [ 1.08763897e+00, -4.89311107e-02,  0.00000000e+00 ...  6.31596670e-02,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 7.24852324e-01,  8.17539403e-04,  0.00000000e+00 ... -6.14322210e-03,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 3.38216603e-01, -1.16487248e-02, -3.33991344e-03 ... -4.03530449e-02,  4.27061412e-03,  2.49097142e-02]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a83c8f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1868997, 6], dtype=Float32, value=\n",
       "[[ 7.52748398e-04,  1.10478402e-04,  0.00000000e+00,  6.30408875e-04,  0.00000000e+00,  6.06322777e-04],\n",
       " [ 3.75780500e-02, -9.07959417e-03,  1.08092360e-03,  2.29724422e-02, -1.66198424e-05,  3.18249501e-02],\n",
       " [ 4.23792526e-02, -9.03332140e-03, -6.90772067e-05,  1.69404075e-02,  1.09453096e-04,  1.84522085e-02],\n",
       " ...\n",
       " [ 1.05965801e-03,  1.93561194e-04,  0.00000000e+00,  5.99977211e-04,  0.00000000e+00,  6.99713477e-04],\n",
       " [ 9.83286276e-03,  2.90450011e-03,  0.00000000e+00,  4.25822381e-03,  0.00000000e+00,  6.12206990e-03],\n",
       " [ 3.67839336e-02, -9.86265857e-03,  1.23296503e-03,  2.26253327e-02,  1.72280517e-04,  2.93803141e-02]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef66989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  23%|████████▏                          | 72891/312500 [06:27<21:17, 187.62it/s, loss=7.2506537e-06]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor, Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "from mindspore import context\n",
    "from mindspore.dataset import Dataset\n",
    "from mindspore.common.initializer import Normal\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the context to use CPU or GPU if available\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "# Generate some random data for demonstration purposes\n",
    "num_samples = 100000\n",
    "num_features = 9\n",
    "num_labels = 6\n",
    "\n",
    "# Generate random tabular data and labels\n",
    "data = x_train_ts \n",
    "labels = y_train_ts \n",
    "\n",
    "# Define the regression model\n",
    "class RegressionModel(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Dense(num_features, 64, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(64, 32, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(32, num_labels, weight_init=Normal(0.02))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create a custom dataset\n",
    "def generator():\n",
    "    for i in range(num_samples):\n",
    "        yield data[i], labels[i]\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = ms.dataset.GeneratorDataset(generator, column_names=[\"data\", \"labels\"], shuffle=False)\n",
    "dataloader = dataset.batch(batch_size=32, drop_remainder=True)\n",
    "\n",
    "# Create the model and loss function\n",
    "net = RegressionModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=0.001)\n",
    "\n",
    "# Wrap the network with loss function\n",
    "net_with_loss = nn.WithLossCell(net, loss_fn)\n",
    "\n",
    "# Create train network\n",
    "train_network = nn.TrainOneStepCell(net_with_loss, optimizer).set_train()\n",
    "\n",
    "# Training\n",
    "epochs = 100\n",
    "total_steps = num_samples // 32 * epochs\n",
    "\n",
    "with tqdm(total=total_steps, desc=\"Training Progress\") as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            data_batch, label_batch = batch\n",
    "\n",
    "            loss = train_network(data_batch, label_batch)\n",
    "            pbar.set_postfix({\"loss\": loss.asnumpy()})\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.refresh()\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "02358c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
